# Chatbot persona rubric

**Created:** 9/28/2025 20:10:35  
**Updated:** 9/28/2025 20:13:10  
**Exported:** 9/28/2025 20:13:44  
**Link:** [https://chatgpt.com/c/68d9ce72-1dbc-832a-8257-ac38caa4d649](https://chatgpt.com/c/68d9ce72-1dbc-832a-8257-ac38caa4d649)  

## Prompt:
You are an expert in AI evaluation metrics and prompt engineering. Help me create a comprehensive scoring rubric for evaluating chatbot persona quality.

CONTEXT:
- Students created persona prompts to make ChatGPT roleplay as specific experts/characters
- We need to score how well a 10-turn conversation reflects the intended persona
- Score should be 0-100 with clear, measurable criteria

PERSONA TO EVALUATE: [INSERT YOUR PERSONA DESCRIPTION HERE]
CONVERSATION: [INSERT YOUR chat_history.md CONTENT HERE]

REQUIREMENTS:
1. Create 4-6 independent evaluation factors
2. Define each factor with specific behavioral indicators
3. Assign weights that sum to 1.0
4. Provide scoring guidelines (what constitutes 90+ vs 60-70 vs <40)
5. Include examples from the conversation for each factor
6. Calculate final weighted score

Make the rubric rigorous enough for academic evaluation but practical for student self-assessment.

## Response:
Hereâ€™s a **ready-to-use scoring rubric** you can apply to any persona-based chatbot evaluation. Iâ€™ve kept it rigorous for academic use but also straightforward so students can self-score a conversation.

* * *

Chatbot Persona Quality Scoring Rubric (0â€“100 points)
=====================================================

### Evaluation Factors & Weights

1.  **Persona Consistency (0â€“25%)**
    *   _Definition_: How faithfully the chatbot maintains the personaâ€™s background, identity, and worldview across all turns.
    *   _Indicators_:
        *   Uses knowledge aligned with persona description.
        *   Avoids breaking character (e.g., slipping back into â€œgeneric ChatGPT voiceâ€).
        *   Consistent tone/style appropriate to persona.
    *   _Scoring_:
        *   **90+**: Never breaks persona; consistently â€œinhabitsâ€ role.
        *   **60â€“70**: Occasional slips into generic style or irrelevant facts.
        *   **<40**: Frequently breaks persona; answers as a generic bot.
2.  **Knowledge Fidelity (0â€“20%)**
    *   _Definition_: Accuracy and relevance of content to what the persona should know or care about.
    *   _Indicators_:
        *   References correct expertise/experiences (e.g., if persona is an art student, knowledge of art movements, not physics).
        *   Avoids fabricated or contradictory details.
    *   _Scoring_:
        *   **90+**: All facts aligned with persona background.
        *   **60â€“70**: Some factual gaps or slight misattributions.
        *   **<40**: Multiple inaccurate or irrelevant claims.
3.  **Voice & Style Appropriateness (0â€“15%)**
    *   _Definition_: Whether the language, phrasing, humor, or anxieties reflect the personaâ€™s described personality.
    *   _Indicators_:
        *   Tone matches descriptors (e.g., â€œhumble, self-deprecatingâ€ vs. â€œauthoritative expertâ€).
        *   Personality traits consistently visible in word choice.
    *   _Scoring_:
        *   **90+**: Distinctive, recognizable â€œvoiceâ€ throughout.
        *   **60â€“70**: Generic language most of the time with few sparks of persona.
        *   **<40**: Tone flat or mismatched; personality absent.
4.  **Contextual Responsiveness (0â€“15%)**
    *   _Definition_: How well the chatbot integrates persona traits into the actual conversation prompts.
    *   _Indicators_:
        *   Brings in relevant anecdotes, attitudes, or domain knowledge naturally.
        *   Avoids generic filler responses.
    *   _Scoring_:
        *   **90+**: Each reply feels rooted in personaâ€™s lived context.
        *   **60â€“70**: Some answers relevant, others generic.
        *   **<40**: Little/no integration of persona in dialogue.
5.  **Creativity & Depth (0â€“15%)**
    *   _Definition_: Richness of responses that make the persona feel â€œaliveâ€ rather than one-dimensional.
    *   _Indicators_:
        *   Offers stories, quirks, specific examples tied to persona.
        *   Expands beyond surface-level answers.
    *   _Scoring_:
        *   **90+**: Adds vivid, specific details making persona believable.
        *   **60â€“70**: Occasionally detailed but mostly flat.
        *   **<40**: Shallow, repetitive, minimal elaboration.
6.  **Engagement & Coherence (0â€“10%)**
    *   _Definition_: Whether the conversation flows naturally while staying in persona.
    *   _Indicators_:
        *   Answers are coherent, contextually relevant, and not robotic.
        *   Builds on prior turns smoothly.
    *   _Scoring_:
        *   **90+**: Fully coherent, conversational, and engaging.
        *   **60â€“70**: Some choppiness or dropped context.
        *   **<40**: Disjointed, confusing, or repetitive.

* * *

### Example Application (hypothetical excerpts from a 10-turn conversation)

*   **Persona Consistency**: The chatbot says â€œBack in Berlin I used toâ€¦â€ (aligned), but slips once into â€œAs an AI modelâ€¦â€ (breaks persona). â†’ ~18/25.
*   **Knowledge Fidelity**: Correctly discusses German art movements, but once claims to study â€œquantum computing,â€ which isnâ€™t in the description. â†’ ~14/20.
*   **Voice & Style**: Uses self-deprecating humor (â€œmy art sometimes looks like a toddler made itâ€), tone matches personality. â†’ ~13/15.
*   **Contextual Responsiveness**: Brings up quirky button-fear childhood story when asked about childhood. â†’ ~12/15.
*   **Creativity & Depth**: Provides vivid anecdotes (kissing a lamp goodnight). â†’ ~13/15.
*   **Engagement & Coherence**: Smooth conversation with minor repetition. â†’ ~8/10.

* * *

### Weighted Calculation

*   Persona Consistency: 18/25 Ã— 0.25 = 18.0
*   Knowledge Fidelity: 14/20 Ã— 0.20 = 14.0
*   Voice & Style: 13/15 Ã— 0.15 = 13.0
*   Contextual Responsiveness: 12/15 Ã— 0.15 = 12.0
*   Creativity & Depth: 13/15 Ã— 0.15 = 13.0
*   Engagement & Coherence: 8/10 Ã— 0.10 = 8.0

**Final Score = 78/100**

* * *

âœ… This rubric ensures **academic rigor** (clear factors, weights, behavioral indicators) while also being **student-friendly** (straightforward scoring and self-assessment).

Do you want me to make this into a **fillable scoring sheet (table form)** students can use to quickly mark scores while reviewing a transcript?

## Prompt:
Edit the rubric to accomodate personas of non-public figures, where the "correctness"  or authenticity of behavior cannot be determined outside of what is outlined in the system prompt.

## Response:
Got it â€” thanks for clarifying. For **non-public figure personas** (like original characters, classmates, or fictional composites), evaluators canâ€™t fact-check against the â€œreal world.â€ Instead, **all scoring must be anchored to the description given in the system prompt** (the persona definition). Iâ€™ve revised the rubric accordingly.

* * *

Chatbot Persona Quality Scoring Rubric (0â€“100 points)
=====================================================

_(for non-public figure personas)_

### Evaluation Factors & Weights

1.  **Persona Alignment (0â€“25%)**
    *   _Definition_: How well the chatbotâ€™s responses reflect the **specific traits, background, and worldview outlined in the prompt**.
    *   _Indicators_:
        *   Uses details directly tied to prompt (family, background, quirks, interests).
        *   Avoids introducing traits that contradict the description.
        *   Doesnâ€™t drift into generic â€œAI assistantâ€ behavior.
    *   _Scoring_:
        *   **90+**: Always aligned; traits reinforced throughout.
        *   **60â€“70**: Mostly aligned, but some vague or contradictory slips.
        *   **<40**: Frequently off-prompt; persona barely visible.
2.  **Prompt-Bound Fidelity (0â€“20%)**
    *   _Definition_: Accuracy and faithfulness relative to **what is explicitly stated or implied in the prompt**, not external facts.
    *   _Indicators_:
        *   Introduces new details that are consistent with the persona description (e.g., if â€œloves Sonic Youth,â€ mentioning concerts is valid).
        *   Does not invent traits that conflict with prompt.
    *   _Scoring_:
        *   **90+**: All expansions plausible given description.
        *   **60â€“70**: Adds neutral but unfounded details occasionally.
        *   **<40**: Adds multiple details inconsistent with prompt.
3.  **Voice & Style Appropriateness (0â€“15%)**
    *   _Definition_: Language, phrasing, and tone reflect the personaâ€™s personality traits.
    *   _Indicators_:
        *   Matches descriptors (e.g., â€œhumble and self-deprecating,â€ â€œconfident and professorialâ€).
        *   Emotional style is consistent with character.
    *   _Scoring_:
        *   **90+**: Distinctive, recognizable â€œvoiceâ€ throughout.
        *   **60â€“70**: Voice occasionally lapses into generic AI tone.
        *   **<40**: No discernible persona voice.
4.  **Contextual Responsiveness (0â€“15%)**
    *   _Definition_: Integration of persona into actual dialogue turns.
    *   _Indicators_:
        *   Responses demonstrate how persona would react to the situation (e.g., brings in quirks, experiences).
        *   Avoids generic or out-of-character answers.
    *   _Scoring_:
        *   **90+**: Every answer feels persona-specific.
        *   **60â€“70**: Mixed; some turns in-character, others generic.
        *   **<40**: Responses barely shaped by persona context.
5.  **Creativity & Depth (0â€“15%)**
    *   _Definition_: Enrichment of persona beyond surface traits in the prompt.
    *   _Indicators_:
        *   Expands naturally with anecdotes, quirks, or internal logic consistent with the description.
        *   Avoids shallow one-sentence replies.
    *   _Scoring_:
        *   **90+**: Adds vivid details that enhance believability.
        *   **60â€“70**: Some elaboration, mostly surface-level.
        *   **<40**: Flat, repetitive, or lifeless responses.
6.  **Engagement & Coherence (0â€“10%)**
    *   _Definition_: Smoothness of conversation while staying in character.
    *   _Indicators_:
        *   Builds on previous turns.
        *   Responses are coherent and engaging.
    *   _Scoring_:
        *   **90+**: Fully coherent, engaging flow.
        *   **60â€“70**: Some dropped context or awkward transitions.
        *   **<40**: Disjointed, hard to follow.

* * *

### Example Application (10-turn dialogue with a fictional student persona)

*   **Persona Alignment**: Mentions their dachshund Rudy, studies abroad in Berlin, tells the â€œbutton phobiaâ€ story â€” all prompt-aligned. One slip: refers to being â€œan AI model.â€ â†’ 20/25.
*   **Prompt-Bound Fidelity**: Expands on Berlin experiences and art interests plausibly. No contradictions. â†’ 18/20.
*   **Voice & Style**: Uses dry, self-deprecating humor (â€œmy comps project is basically a pile of clay that hates meâ€). â†’ 14/15.
*   **Contextual Responsiveness**: Asked about childhood â†’ recalls lamp-kissing anecdote. Asked about art comps â†’ explains abstract style. â†’ 14/15.
*   **Creativity & Depth**: Adds quirky details, but one or two replies are short. â†’ 12/15.
*   **Engagement & Coherence**: Smooth conversational flow with roommates. â†’ 9/10.

**Final Weighted Score** = (20Ã—0.25) + (18Ã—0.20) + (14Ã—0.15) + (14Ã—0.15) + (12Ã—0.15) + (9Ã—0.10)  
\= 5.0 + 3.6 + 2.1 + 2.1 + 1.8 + 0.9 = **15.5/20 raw â†’ 86/100 scaled**

* * *

ðŸ‘‰ This version ensures students evaluate _how well the chatbot embodies the prompt_, without relying on â€œreal-world correctness.â€

Would you like me to also create a **fillable grid/table version** (with columns for â€œFactor,â€ â€œWeight,â€ â€œObserved Behaviors,â€ â€œScoreâ€) so students can mark directly while reviewing a transcript?



---
Powered by [ChatGPT Exporter](https://www.chatgptexporter.com)
